{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertConfig, BertTokenizer\n",
    "import json\n",
    "import pandas as pd\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext import data\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import (TensorDataset, random_split,\n",
    "                              RandomSampler, DataLoader,\n",
    "                              SequentialSampler)\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=54)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./dataset/train.csv')\n",
    "test_data = pd.read_csv('./dataset/test.csv')\n",
    "test_labels = pd.read_csv('./dataset/test_labels.csv')\n",
    "test = pd.merge(test_data, test_labels, on='id')\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train: (159571, 8), test:  (153164, 8)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'train: {train.shape}, test:  {test.shape}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove long sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 200\n",
    "TRAIN_SIZE = 5000\n",
    "TEST_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data, size, ratio):\n",
    "    X, y = data['comment_text'].values, data['toxic'].values\n",
    "    lengths = np.array([len(x.split()) for x in X])\n",
    "    idxs = np.where(lengths <= MAX_LEN)[0]\n",
    "    X, y = X[idxs], y[idxs]\n",
    "    \n",
    "    lengths = np.array([len(x) for x in X])\n",
    "    idxs = np.where(lengths <= 512)[0]\n",
    "    X, y = X[idxs], y[idxs]\n",
    "\n",
    "\n",
    "    toxic = np.where(y == 1)[0]\n",
    "    normal = np.where(y == 0)[0]\n",
    "    idxs_toxic = np.random.choice(toxic, round(size * ratio), replace=False)\n",
    "    idxs_normal = np.random.choice(normal, round(size * (1 - ratio)), replace=False)\n",
    "\n",
    "    X = np.concatenate([X[idxs_toxic], X[idxs_normal]])\n",
    "    y = np.concatenate([y[idxs_toxic], y[idxs_normal]])\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_data(train, TRAIN_SIZE, 0.5)\n",
    "X_test, y_test = get_data(test, TEST_SIZE, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Train: normal - 2500 toxic - 2500'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Train: normal - {len(np.where(y_train == 0)[0])} toxic - {len(np.where(y_train == 1)[0])}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test: normal - 200 toxic - 300'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Test: normal - {len(np.where(y_test == 0)[0])} toxic - {len(np.where(y_test == 1)[0])}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(X):\n",
    "    X_split = [t.split() for t in X]\n",
    "    text_field = data.Field()\n",
    "    text_field.build_vocab(X_split, max_size=10000)\n",
    "    return text_field\n",
    "\n",
    "def pad(seq, max_len):\n",
    "    if len(seq) < max_len:\n",
    "        seq = seq + ['<pad>'] * (max_len - len(seq))\n",
    "    return seq[0:max_len]\n",
    "\n",
    "def to_indexes(vocab, words):\n",
    "    return [vocab.stoi[w] for w in words]\n",
    "\n",
    "def to_dataset(x, y, y_real):\n",
    "    torch_x = torch.tensor(x, dtype=torch.long)\n",
    "    torch_y = torch.tensor(y, dtype=torch.float)\n",
    "    torch_real_y = torch.tensor(y_real, dtype=torch.long)\n",
    "    return TensorDataset(torch_x, torch_y, torch_real_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers,\n",
    "                 bidirectional, dropout, batch_size):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "\n",
    "        self.rnn = nn.LSTM(self.embedding.embedding_dim,\n",
    "                           hidden_dim,\n",
    "                           num_layers=n_layers,\n",
    "                           bidirectional=bidirectional,\n",
    "                           dropout=dropout)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text, text_lengths=None):\n",
    "        x = self.embedding(text)\n",
    "        x, hidden = self.rnn(x)\n",
    "        hidden, cell = hidden\n",
    "        hidden = self.dropout(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1))\n",
    "        x = self.fc(hidden)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model):\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 2, gamma=0.9)\n",
    "    return optimizer, scheduler\n",
    "\n",
    "def epoch_train_func(model, dataset, loss_func, batch_size):\n",
    "    train_loss = 0\n",
    "    train_sampler = RandomSampler(dataset)\n",
    "    data_loader = DataLoader(dataset, sampler=train_sampler,\n",
    "                             batch_size=batch_size,\n",
    "                             drop_last=True)\n",
    "    model.train()\n",
    "    optimizer, scheduler = get_optimizer(model)\n",
    "    for i, (text, bert_prob, real_label) in enumerate(tqdm(data_loader, desc='Train')):\n",
    "        model.zero_grad()\n",
    "        output = model(text.t(), None).squeeze(1)\n",
    "        loss = loss_func(output, bert_prob, real_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    scheduler.step()\n",
    "    return train_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_evaluate_func(model, eval_dataset, loss_func, batch_size):\n",
    "    eval_sampler = SequentialSampler(eval_dataset)\n",
    "    data_loader = DataLoader(eval_dataset, sampler=eval_sampler,\n",
    "                             batch_size=batch_size,\n",
    "                             drop_last=True)\n",
    "\n",
    "    eval_loss = 0.0\n",
    "    model.eval()\n",
    "    for i, (text, bert_prob, real_label) in enumerate(tqdm(data_loader, desc='Val')):\n",
    "        output = model(text.t(), None).squeeze(1)\n",
    "        loss = loss_func(output, bert_prob, real_label)\n",
    "        eval_loss += loss.item()\n",
    "\n",
    "    return eval_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMBaseline(object):\n",
    "    vocab_name = 'text_vocab.pt'\n",
    "    weights_name = 'simple_lstm.pt'\n",
    "\n",
    "    def __init__(self, settings):\n",
    "        self.settings = settings\n",
    "        self.criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def loss(self, output, bert_prob, real_label):\n",
    "        return self.criterion(output, real_label.float())\n",
    "\n",
    "    def model(self, text_field):\n",
    "        model = SimpleLSTM(\n",
    "            input_dim=len(text_field.vocab),\n",
    "            embedding_dim=64,\n",
    "            hidden_dim=128,\n",
    "            output_dim=1,\n",
    "            n_layers=1,\n",
    "            bidirectional=True,\n",
    "            dropout=0.5,\n",
    "            batch_size=self.settings['train_batch_size'])\n",
    "        return model\n",
    "\n",
    "    def train(self, X, y, y_real, output_dir):\n",
    "        max_len = self.settings['max_seq_length']\n",
    "        text_field = get_vocab(X)\n",
    "\n",
    "        X_split = [t.split() for t in X]\n",
    "        X_pad = [pad(s, max_len) for s in tqdm(X_split, desc='pad')]\n",
    "        X_index = [to_indexes(text_field.vocab, s) for s in tqdm(X_pad, desc='to index')]\n",
    "\n",
    "        dataset = to_dataset(X_index, y, y_real)\n",
    "        val_len = int(len(dataset) * 0.1)\n",
    "        train_dataset, val_dataset = random_split(dataset, (len(dataset) - val_len, val_len))\n",
    "\n",
    "        model = self.model(text_field)\n",
    "        \n",
    "        self.full_train(model, train_dataset, val_dataset, output_dir)\n",
    "        torch.save(text_field, os.path.join(output_dir, self.vocab_name))\n",
    "        \n",
    "        return model, text_field.vocab\n",
    "\n",
    "    def full_train(self, model, train_dataset, val_dataset, output_dir):\n",
    "        train_settings = self.settings\n",
    "        num_train_epochs = train_settings['num_train_epochs']\n",
    "        best_eval_loss = 100000\n",
    "        losses = []\n",
    "        for epoch in tqdm(range(num_train_epochs), desc='Epochs'):\n",
    "            train_loss = epoch_train_func(model, train_dataset, self.loss, self.settings['train_batch_size'])\n",
    "            eval_loss = epoch_evaluate_func(model, val_dataset, self.loss, self.settings['eval_batch_size'])\n",
    "            \n",
    "            print(f'Epoch: {epoch} loss: {eval_loss}')\n",
    "            losses.append(eval_loss)\n",
    "            \n",
    "            if eval_loss < best_eval_loss:\n",
    "                best_eval_loss = eval_loss\n",
    "                torch.save(model.state_dict(), os.path.join(output_dir, self.weights_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_settings = {\n",
    "    'max_seq_length': MAX_LEN,\n",
    "    'num_train_epochs': 0,\n",
    "    'train_batch_size': 32,\n",
    "    'eval_batch_size': 32,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = LSTMBaseline(lstm_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec7aa6642834eae8b417d10e0b56a78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='pad', max=5000.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26dd0faaef594e46872dcafcee01689a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='to index', max=5000.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abaecf63f60e4818a56fa87a9b7e48cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Epochs', max=1.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model, vocab = trainer.train(X_train, y_train, y_train, './output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(X, y, vocab):\n",
    "    X_split = [t.split() for t in X]\n",
    "    X_pad = [pad(s, MAX_LEN) for s in tqdm(X_split, desc='pad')]\n",
    "    X_index = [to_indexes(vocab, s) for s in tqdm(X_pad, desc='to index')]\n",
    "    X = torch.transpose(torch.tensor(X_index, dtype=torch.long), 1, 0)\n",
    "    \n",
    "    y = torch.tensor(y, dtype=torch.float)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, vocab, X, y):\n",
    "    X_test, y_test = preprocessing(X, y, vocab)\n",
    "    softmax = nn.Sigmoid()\n",
    "#     softmax = nn.Softmax()\n",
    "    y_pred = softmax(model(X_test)).detach().numpy()\n",
    "    y_pred = np.around(y_pred)\n",
    "#     y_pred = np.argmax(y_pred, axis=1)\n",
    "    accuracy = accuracy_score(y_pred, y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleLSTM(\n",
       "  (embedding): Embedding(10002, 64)\n",
       "  (rnn): LSTM(64, 128, dropout=0.5, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./output/simple_lstm.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd82b07dc5f4f5c8c1c8b902ab1c60e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='pad', max=500.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "585519f57d3942609395f9bff7a1ff85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='to index', max=500.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Accuracy: 0.564'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Accuracy: {test(model, vocab, X_test, y_test)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMDistilled(LSTMBaseline):\n",
    "    vocab_name = 'distil_text_vocab.pt'\n",
    "    weights_name = 'distil_lstm.pt'\n",
    "\n",
    "    def __init__(self, settings):\n",
    "        super(LSTMDistilled, self).__init__(settings)\n",
    "        self.criterion_mse = torch.nn.MSELoss()\n",
    "        self.criterion_ce = torch.nn.CrossEntropyLoss()\n",
    "        self.a = 0.5\n",
    "\n",
    "    def loss(self, output, bert_prob, real_label):\n",
    "        return self.a * self.criterion_ce(output, real_label) + (1 - self.a) * self.criterion_mse(output, bert_prob)\n",
    "\n",
    "    def model(self, text_field):\n",
    "        model = SimpleLSTM(\n",
    "            input_dim=len(text_field.vocab),\n",
    "            embedding_dim=64,\n",
    "            hidden_dim=128,\n",
    "            output_dim=2,\n",
    "            n_layers=1,\n",
    "            bidirectional=True,\n",
    "            dropout=0.5,\n",
    "            batch_size=self.settings['train_batch_size'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bert = torch.tensor([tokenizer.encode(x, add_special_tokens=True, pad_to_max_length=True) for x in X_train])\n",
    "y_bert = torch.tensor(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bert = torch.tensor(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = BertForSequenceClassification.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = bert(X_bert, labels=y_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
